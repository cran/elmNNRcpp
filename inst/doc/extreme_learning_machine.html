<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Lampros Mouselimis" />

<meta name="date" content="2018-07-21" />

<title>Extreme Learning Machine</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Extreme Learning Machine</h1>
<h4 class="author"><em>Lampros Mouselimis</em></h4>
<h4 class="date"><em>2018-07-21</em></h4>



<p>As of 2018-06-17 the <a href="https://CRAN.R-project.org/package=elmNN">elmNN</a> package was archived and due to the fact that it was one of the machine learning functions that I used when I started learning R (it returns the output results pretty fast too) plus that I had to utilize the package last week for a personal task I decided to reimplement the R code in Rcpp. It didn’t take long because the R package was written, initially by the author, in a clear way. In the next lines I’ll explain the differences and the functionality just for reference.</p>
<p><br></p>
<div id="differences-between-the-elmnn-r-package-and-the-elmnnrcpp-rcpp-package" class="section level3">
<h3>Differences between the elmNN (R package) and the elmNNRcpp (Rcpp Package)</h3>
<ul>
<li>The reimplementation assumes that both the predictors ( <em>x</em> ) and the response variable ( <em>y</em> ) are in the form of a matrix. This means that <em>character</em>, <em>factor</em> or <em>boolean</em> columns have to be transformed (onehot encoded would be an option) before using either the <em>elm_train</em> or the <em>elm_predict</em> function.</li>
<li>The output predictions are in the form of a matrix. In case of regression the matrix has one column whereas in case of classification the number of columns equals the number of unique labels</li>
<li>In case of classification the unique labels should begin from 0 and the difference between the unique labels should not be greater than 1. For instance, <em>unique_labels = c(0, 1, 2, 3)</em> are acceptable whereas the following case will raise an error : <em>unique_labels = c(0, 2, 3, 4)</em></li>
<li>I renamed the <em>poslin</em> activation to <em>relu</em> as it’s easier to remember ( both share the same properties ). Moreover I added the <em>leaky_relu_alpha</em> parameter so that if the value is greater than 0.0 a leaky-relu-activation for the single-hidden-layer can be used.</li>
<li>The initilization weights in the <em>elmNN</em> were set by default to uniform in the range [-1,1] <em>( ’uniform_negative’ )</em> . I added two more options : <em>‘normal_gaussian’ ( in the range [0,1] )</em> and <em>‘uniform_positive’ ( in the range [0,1] )</em> too</li>
<li>The user has the option to include or exclude <em>bias</em> of the one-layer feed-forward neural network</li>
</ul>
<p><br></p>
</div>
<div id="the-elmnnrcpp-functions" class="section level3">
<h3>The elmNNRcpp functions</h3>
<p>The functions included in the <em>elmNNRcpp</em> package are the following and details for each parameter can be found in the package documentation,</p>
<p><br></p>
<table style="width:29%;">
<colgroup>
<col width="29%"></col>
</colgroup>
<thead>
<tr class="header">
<th align="center">elmNNRcpp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>elm_train</strong>(x, y, nhid, actfun, init_weights = “normal_gaussian”, bias = FALSE, …)</td>
</tr>
<tr class="even">
<td align="center"><strong>elm_predict</strong>(elm_train_object, newdata, normalize = FALSE)</td>
</tr>
<tr class="odd">
<td align="center"><strong>onehot_encode</strong>(y)</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div id="elmnnrcpp-in-case-of-regression" class="section level3">
<h3>elmNNRcpp in case of Regression</h3>
<p>The following code chunk gives some details on how to use the <em>elm_train</em> in case of regression and compares the results with the <em>lm ( linear model )</em> base function,</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the data and split it in two parts</span>
<span class="co">#----------------------------------------</span>

<span class="kw">data</span>(Boston, <span class="dt">package =</span> <span class="st">'KernelKnn'</span>)

<span class="kw">library</span>(elmNNRcpp)</code></pre></div>
<pre><code>## Loading required package: KernelKnn</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Boston =<span class="st"> </span><span class="kw">as.matrix</span>(Boston)
<span class="kw">dimnames</span>(Boston) =<span class="st"> </span><span class="ot">NULL</span>

X =<span class="st"> </span>Boston[, <span class="op">-</span><span class="kw">dim</span>(Boston)[<span class="dv">2</span>]]
xtr =<span class="st"> </span>X[<span class="dv">1</span><span class="op">:</span><span class="dv">350</span>, ]
xte =<span class="st"> </span>X[<span class="dv">351</span><span class="op">:</span><span class="kw">nrow</span>(X), ]


<span class="co"># prepare / convert the train-data-response to a one-column matrix</span>
<span class="co">#-----------------------------------------------------------------</span>

ytr =<span class="st"> </span><span class="kw">matrix</span>(Boston[<span class="dv">1</span><span class="op">:</span><span class="dv">350</span>, <span class="kw">dim</span>(Boston)[<span class="dv">2</span>]], <span class="dt">nrow =</span> <span class="kw">length</span>(Boston[<span class="dv">1</span><span class="op">:</span><span class="dv">350</span>, <span class="kw">dim</span>(Boston)[<span class="dv">2</span>]]),
             
             <span class="dt">ncol =</span> <span class="dv">1</span>)


<span class="co"># perform a fit and predict [ elmNNRcpp ]</span>
<span class="co">#----------------------------------------</span>

fit_elm =<span class="st"> </span><span class="kw">elm_train</span>(xtr, ytr, <span class="dt">nhid =</span> <span class="dv">1000</span>, <span class="dt">actfun =</span> <span class="st">'purelin'</span>,
                    
                    <span class="dt">init_weights =</span> <span class="st">&quot;uniform_negative&quot;</span>, <span class="dt">bias =</span> <span class="ot">TRUE</span>, <span class="dt">verbose =</span> T)</code></pre></div>
<pre><code>## Input weights will be initialized ...
## Dot product of input weights and data starts ...
## Bias will be added to the dot product ...
## 'purelin' activation function will be utilized ...
## The computation of the Moore-Pseudo-inverse starts ...
## The computation is finished!
## 
## Time to complete : 0.09782553 secs</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pr_te_elm =<span class="st"> </span><span class="kw">elm_predict</span>(fit_elm, xte)



<span class="co"># perform a fit and predict [ lm ]</span>
<span class="co">#----------------------------------------</span>

<span class="kw">data</span>(Boston, <span class="dt">package =</span> <span class="st">'KernelKnn'</span>)

fit_lm =<span class="st"> </span><span class="kw">lm</span>(medv<span class="op">~</span>., <span class="dt">data =</span> Boston[<span class="dv">1</span><span class="op">:</span><span class="dv">350</span>, ])

pr_te_lm =<span class="st"> </span><span class="kw">predict</span>(fit_lm, <span class="dt">newdata =</span> Boston[<span class="dv">351</span><span class="op">:</span><span class="kw">nrow</span>(X), ])



<span class="co"># evaluation metric</span>
<span class="co">#------------------</span>

rmse =<span class="st"> </span><span class="cf">function</span> (y_true, y_pred) {
  
  out =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_true <span class="op">-</span><span class="st"> </span>y_pred)<span class="op">^</span><span class="dv">2</span>))
  
  out
}


<span class="co"># test data response variable</span>
<span class="co">#----------------------------</span>

yte =<span class="st"> </span>Boston[<span class="dv">351</span><span class="op">:</span><span class="kw">nrow</span>(X), <span class="kw">dim</span>(Boston)[<span class="dv">2</span>]]


<span class="co"># mean-squared-error for 'elm' and 'lm'</span>
<span class="co">#--------------------------------------</span>

<span class="kw">cat</span>(<span class="st">'the rmse error for extreme-learning-machine is :'</span>, <span class="kw">rmse</span>(yte, pr_te_elm[, <span class="dv">1</span>]), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</code></pre></div>
<pre><code>## the rmse error for extreme-learning-machine is : 22.00705</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(<span class="st">'the rmse error for liner-model is :'</span>, <span class="kw">rmse</span>(yte, pr_te_lm), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</code></pre></div>
<pre><code>## the rmse error for liner-model is : 23.36543</code></pre>
<p><br></p>
</div>
<div id="elmnnrcpp-in-case-of-classification" class="section level3">
<h3>elmNNRcpp in case of Classification</h3>
<p>The following code script illustrates how <em>elm_train</em> can be used in classification and compares the results with the <em>glm ( Generalized Linear Models )</em> base function,</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the data</span>
<span class="co">#--------------</span>

<span class="kw">data</span>(ionosphere, <span class="dt">package =</span> <span class="st">'KernelKnn'</span>)

y_class =<span class="st"> </span>ionosphere[, <span class="kw">ncol</span>(ionosphere)]

x_class =<span class="st"> </span>ionosphere[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="kw">ncol</span>(ionosphere))]     <span class="co"># second column has 1 unique value</span>

x_class =<span class="st"> </span><span class="kw">scale</span>(x_class[, <span class="op">-</span><span class="kw">ncol</span>(x_class)])

x_class =<span class="st"> </span><span class="kw">as.matrix</span>(x_class)                        <span class="co"># convert to matrix</span>
<span class="kw">dimnames</span>(x_class) =<span class="st"> </span><span class="ot">NULL</span> 



<span class="co"># split data in train-test</span>
<span class="co">#-------------------------</span>

xtr_class =<span class="st"> </span>x_class[<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>, ]                    
xte_class =<span class="st"> </span>x_class[<span class="dv">201</span><span class="op">:</span><span class="kw">nrow</span>(ionosphere), ]

ytr_class =<span class="st"> </span><span class="kw">as.numeric</span>(y_class[<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>])
yte_class =<span class="st"> </span><span class="kw">as.numeric</span>(y_class[<span class="dv">201</span><span class="op">:</span><span class="kw">nrow</span>(ionosphere)])

ytr_class =<span class="st"> </span><span class="kw">onehot_encode</span>(ytr_class <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)                                     <span class="co"># class labels should begin from 0 (subtract 1)</span>


<span class="co"># perform a fit and predict [ elmNNRcpp ]</span>
<span class="co">#----------------------------------------</span>

fit_elm_class =<span class="st"> </span><span class="kw">elm_train</span>(xtr_class, ytr_class, <span class="dt">nhid =</span> <span class="dv">1000</span>, <span class="dt">actfun =</span> <span class="st">'relu'</span>,
                          
                          <span class="dt">init_weights =</span> <span class="st">&quot;uniform_negative&quot;</span>, <span class="dt">bias =</span> <span class="ot">TRUE</span>, <span class="dt">verbose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Input weights will be initialized ...
## Dot product of input weights and data starts ...
## Bias will be added to the dot product ...
## 'relu' activation function will be utilized ...
## The computation of the Moore-Pseudo-inverse starts ...
## The computation is finished!
## 
## Time to complete : 0.03874469 secs</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pr_elm_class =<span class="st"> </span><span class="kw">elm_predict</span>(fit_elm_class, xte_class, <span class="dt">normalize =</span> <span class="ot">FALSE</span>)

pr_elm_class =<span class="st"> </span><span class="kw">max.col</span>(pr_elm_class, <span class="dt">ties.method =</span> <span class="st">&quot;random&quot;</span>)



<span class="co"># perform a fit and predict [ glm ]</span>
<span class="co">#----------------------------------------</span>

<span class="kw">data</span>(ionosphere, <span class="dt">package =</span> <span class="st">'KernelKnn'</span>)

fit_glm =<span class="st"> </span><span class="kw">glm</span>(class<span class="op">~</span>., <span class="dt">data =</span> ionosphere[<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>, <span class="op">-</span><span class="dv">2</span>], <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">'logit'</span>))</code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pr_glm =<span class="st"> </span><span class="kw">predict</span>(fit_glm, <span class="dt">newdata =</span> ionosphere[<span class="dv">201</span><span class="op">:</span><span class="kw">nrow</span>(ionosphere), <span class="op">-</span><span class="dv">2</span>], <span class="dt">type =</span> <span class="st">'response'</span>)

pr_glm =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">ifelse</span>(pr_glm <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">2</span>))


<span class="co"># accuracy for 'elm' and 'glm'</span>
<span class="co">#-----------------------------</span>

<span class="kw">cat</span>(<span class="st">'the accuracy for extreme-learning-machine is :'</span>, <span class="kw">mean</span>(yte_class <span class="op">==</span><span class="st"> </span>pr_elm_class), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</code></pre></div>
<pre><code>## the accuracy for extreme-learning-machine is : 0.9337748</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(<span class="st">'the accuracy for glm is :'</span>, <span class="kw">mean</span>(yte_class <span class="op">==</span><span class="st"> </span>pr_glm), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</code></pre></div>
<pre><code>## the accuracy for glm is : 0.8940397</code></pre>
<p><br></p>
</div>
<div id="classify-mnist-digits-using-elmnnrcpp" class="section level3">
<h3>Classify MNIST digits using elmNNRcpp</h3>
<p>I found an interesting <a href="https://www.kaggle.com/robertbm/extreme-learning-machine-example">Python implementation / Code on the web</a> and I thought I give it a try to reproduce the results. I downloaded the MNIST data from my <a href="https://github.com/mlampros/DataSets">Github repository</a> and I used the following parameter setting,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># using system('wget..') on a linux OS </span>
<span class="co">#-------------------------------------</span>

<span class="kw">system</span>(<span class="st">&quot;wget https://raw.githubusercontent.com/mlampros/DataSets/master/mnist.zip&quot;</span>)             

mnist &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">unz</span>(<span class="st">&quot;mnist.zip&quot;</span>, <span class="st">&quot;mnist.csv&quot;</span>), <span class="dt">nrows =</span> <span class="dv">70000</span>, <span class="dt">header =</span> T, 
                    
                    <span class="dt">quote =</span> <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)

x =<span class="st"> </span>mnist[, <span class="op">-</span><span class="kw">ncol</span>(mnist)]

y =<span class="st"> </span>mnist[, <span class="kw">ncol</span>(mnist)]

<span class="co"># using system('wget..') on a linux OS </span>
<span class="co">#-------------------------------------</span>

<span class="kw">system</span>(<span class="st">&quot;wget https://raw.githubusercontent.com/mlampros/DataSets/master/mnist.zip&quot;</span>)             

mnist &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">unz</span>(<span class="st">&quot;mnist.zip&quot;</span>, <span class="st">&quot;mnist.csv&quot;</span>), <span class="dt">nrows =</span> <span class="dv">70000</span>, <span class="dt">header =</span> T, 
                    
                    <span class="dt">quote =</span> <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)

x =<span class="st"> </span>mnist[, <span class="op">-</span><span class="kw">ncol</span>(mnist)]

y =<span class="st"> </span>mnist[, <span class="kw">ncol</span>(mnist)] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>


<span class="co"># use the hog-features as input data</span>
<span class="co">#-----------------------------------</span>

hog =<span class="st"> </span>OpenImageR<span class="op">::</span><span class="kw">HOG_apply</span>(x, <span class="dt">cells =</span> <span class="dv">6</span>, <span class="dt">orientations =</span> <span class="dv">9</span>, <span class="dt">rows =</span> <span class="dv">28</span>, <span class="dt">columns =</span> <span class="dv">28</span>, <span class="dt">threads =</span> <span class="dv">6</span>)

y_expand =<span class="st"> </span>elmNNRcpp<span class="op">::</span><span class="kw">onehot_encode</span>(y <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)


<span class="co"># 4-fold cross-validation</span>
<span class="co">#------------------------</span>

folds =<span class="st"> </span>KernelKnn<span class="op">:::</span><span class="kw">class_folds</span>(<span class="dt">folds =</span> <span class="dv">4</span>, <span class="kw">as.factor</span>(y))
<span class="kw">str</span>(folds)

START =<span class="st"> </span><span class="kw">Sys.time</span>()


fit =<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(folds), <span class="cf">function</span>(x) {
  
  <span class="kw">cat</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>); <span class="kw">cat</span>(<span class="st">'fold'</span>, x, <span class="st">'starts ....'</span>, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)
  
  tmp_fit =<span class="st"> </span>elmNNRcpp<span class="op">::</span><span class="kw">elm_train</span>(<span class="kw">as.matrix</span>(hog[<span class="kw">unlist</span>(folds[<span class="op">-</span>x]), ]), y_expand[<span class="kw">unlist</span>(folds[<span class="op">-</span>x]), ], 
  
                                 <span class="dt">nhid =</span> <span class="dv">2500</span>, <span class="dt">actfun =</span> <span class="st">'relu'</span>, <span class="dt">init_weights =</span> <span class="st">'uniform_negative'</span>,
                                 
                                 <span class="dt">bias =</span> <span class="ot">TRUE</span>, <span class="dt">verbose =</span> <span class="ot">TRUE</span>)
  
  <span class="kw">cat</span>(<span class="st">'******************************************'</span>, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)
  
  tmp_fit
})

END =<span class="st"> </span><span class="kw">Sys.time</span>()

END <span class="op">-</span><span class="st"> </span>START

<span class="co"># Time difference of 5.698552 mins</span>


<span class="kw">str</span>(fit)


<span class="co"># predictions for 4-fold cross validation</span>
<span class="co">#----------------------------------------</span>

test_acc =<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(fit), <span class="cf">function</span>(x) {
  
  pr_te =<span class="st"> </span>elmNNRcpp<span class="op">::</span><span class="kw">elm_predict</span>(fit[[x]], <span class="dt">newdata =</span> <span class="kw">as.matrix</span>(hog[folds[[x]], ]))
  
  pr_max_col =<span class="st"> </span><span class="kw">max.col</span>(pr_te, <span class="dt">ties.method =</span> <span class="st">&quot;random&quot;</span>)
  
  y_true =<span class="st"> </span><span class="kw">max.col</span>(y_expand[folds[[x]], ])
  
  <span class="kw">mean</span>(pr_max_col <span class="op">==</span><span class="st"> </span>y_true)
}))
  
  

test_acc

<span class="co"># [1] 0.9825143 0.9848571 0.9824571 0.9822857</span>


<span class="kw">cat</span>(<span class="st">'Accuracy ( Mnist data ) :'</span>, <span class="kw">round</span>(<span class="kw">mean</span>(test_acc) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>, <span class="dv">2</span>), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)

<span class="co"># Accuracy ( Mnist data ) : 98.3</span></code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
